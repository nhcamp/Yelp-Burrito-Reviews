{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT RUN THE CELL BELOW (it will take forever to compile). Details on functionality included in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### DONT RUN THIS CELL #################################################################\n",
    "\n",
    "### This cell loads in the two JSON files, pulls out all the mexican restaurants from the business JSON and gathers all the\n",
    "## reviews that mention that restaurant. This takes a long time to compile, so I pickled the two DFs to avoid having to\n",
    "# reacess the massive JSON file.\n",
    "\n",
    "business=pd.read_json('business.json',lines='True')\n",
    "mex = business.categories.str.contains('Mexican', na=False)\n",
    "tex_mex = business.categories.str.contains('Tex-Mex', na=False)\n",
    "taqs = business.loc[mex | tex_mex]\n",
    "taqs_dict = {}\n",
    "taqs_id = []\n",
    "for index,data in taqs.iterrows():\n",
    "    taqs_dict[data['business_id']] = data['name']\n",
    "    taqs_id.append(data['business_id'])\n",
    "reviews = []\n",
    "with open('review.json') as fp:\n",
    "    for line in fp:\n",
    "        comment = json.loads(line) \n",
    "        reviews.append(comment)\n",
    "    fp.close()\n",
    "mexican_reviews = [rev for rev in reviews if rev[\"business_id\"] in taqs]  \n",
    "reviews_df = pd.DataFrame(mexican_reviews)\n",
    "reviews_df['Restaurant Name']=reviews_df['business_id'].map(taq_dict)\n",
    "reviews_df['reviews_length'] = reviews_df['text'].apply(len)\n",
    "\n",
    "reviews_df.to_pickle('./mexican_reviews.pkl')   \n",
    "business.to_pickle('./business_info.pkl')\n",
    "\n",
    "## Here on will load the pickled versions of the dataframe created above, perform manipulations and repickle...\n",
    "reviews_path = 'C:/Users/nhcam/Desktop/Springboard/Yelp Burrito Reviews Project/Yelp_Project_Data/mexican_reviews.pkl'\n",
    "business_path = 'C:/Users/nhcam/Desktop/Springboard/Yelp Burrito Reviews Project/Yelp_Project_Data/business_info.pkl'\n",
    "\n",
    "reviews_df = pd.read_pickle(reviews_path)\n",
    "business_df = pd.read_pickle(business_path)\n",
    "\n",
    "\n",
    "#Adding city and state data to the reviews\n",
    "city = {}\n",
    "state = {}\n",
    "for index,data in tqdm(business_df.iterrows()):\n",
    "    city[data['business_id']] = data['city']\n",
    "    state[data['business_id']] = data['state']\n",
    "reviews_df['city'] = reviews_df['business_id'].map(city)\n",
    "reviews_df['state'] = reviews_df['business_id'].map(state)\n",
    "\n",
    "\n",
    "#Adding region to reviews, dropping any row without a US State (there are british and canadian cities included)\n",
    "US_states = ['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL',\n",
    "             'IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT',\n",
    "             'NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI',\n",
    "             'SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']\n",
    "cali = ['CA']\n",
    "west = ['WA','OR','NV','ID','AK','HI','MT','UT','CO','WY','NM','AZ']\n",
    "midwest = ['ND','SD','NE','KS','OK','MN','IA','MO','WI','MI','IL','IN']\n",
    "south = ['LA','MS','AL','TN','NC','SC','GA','FL','TX','AR']\n",
    "noreast = ['KY','OH','WV','PA','MD','DE','NJ','NY','CT','RI','MA','VA','NH','ME','VT']\n",
    "states = [cali,west,midwest,south,noreast]\n",
    "regions = ['California','West','Midwest','South','Northeast']\n",
    "regions_dict={}\n",
    "i = 0\n",
    "for each in tqdm(states):\n",
    "    for indiv in each:\n",
    "        regions_dict[indiv] = regions[i]\n",
    "    i += 1\n",
    "reviews_df['region'] = reviews_df['state'].map(regions_dict)\n",
    "reviews_df = reviews_df.dropna(axis=0)\n",
    "\n",
    "#Mapping labels to stars\n",
    "stars_dict = {5:'Good',4:'Good',3:'Neutral/Bad',2:'Neutral/Bad',1:'Neutral/Bad'}\n",
    "reviews_df['Good/Neutral/Bad'] = reviews_df['stars'].map(stars_dict)\n",
    "\n",
    "#Word tokenize review text and remove punctuation\n",
    "reviews_df = tokenize_and_clean(reviews_df)\n",
    "\n",
    "#Pull out reviews that mention burritos into new df and drop those rows from the reviews df\n",
    "burrito_mention = reviews_df.loc[reviews_df['text'].str.contains('burrito',case=False, regex = False)]\n",
    "reviews_df = reviews_df.loc[~reviews_df['text'].str.contains('burrito',case=False, regex = False)]\n",
    "\n",
    "#Find sentiment of burrito mentions df\n",
    "burrito_mention = find_burrito_sentences_get_sentiment(burrito_mention)\n",
    "\n",
    "#Set and sort index\n",
    "reviews_df.set_index(['business_id','Restaurant Name'],inplace=True)\n",
    "reviews_df.sort_index(inplace=True)\n",
    "burrito_mention.set_index(['business_id', 'Restaurant Name'],inplace=True)\n",
    "burrito_mention.sort_index(inplace=True)\n",
    "\n",
    "#Pickle dataframes\n",
    "reviews_df.to_pickle('./reviews_df.pkl')\n",
    "burrito_mention.to_pickle('./burrito_mentions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions needed for throughout analysis\n",
    "\n",
    "def remove_stopwords_punc(i1):\n",
    "    \"\"\"\n",
    "    Using nltk library's stop words and string.punctuation, this removes them from a tokenized list. Use with df.apply()\n",
    "    \"\"\"\n",
    "    \n",
    "    stop_words = list(stopwords.words('english'))+list(string.punctuation)\n",
    "    minus_stops = [w for w in i1 if w not in stop_words]\n",
    "    return minus_stops\n",
    "\n",
    "def tokenize_and_clean(df):\n",
    "    \"\"\"\n",
    "    Using nltk word tokenize in df.apply() and cleaning using function above.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['text'].str.lower()\n",
    "    df['tokenized_text'] = df['text'].apply(word_tokenize)\n",
    "    df['tokenized_text_cleaned'] = df['tokenized_text'].apply(remove_stopwords_punc)\n",
    "    return df\n",
    "\n",
    "def dummy(doc):\n",
    "    \"\"\"\n",
    "    Used as a placeholder when instantiating a vectorizer as preprocessing and tokenizing already done. Does nothing.\n",
    "    \"\"\"\n",
    "    return doc\n",
    "\n",
    "def split_sentences_return_burrito(st):\n",
    "    \"\"\"Checks for occurence of punctuation that allows splitting of sentences, if found it splits the text into sentences\n",
    "    and then pulls out the sentence that has the word 'burrito' in the sentence.\n",
    "    \"\"\"\n",
    "    if '.' in st:\n",
    "        sentences = re.split(r'[.?!]\\s*', st)\n",
    "        sentences_lower = [sentence.lower() for sentence in sentences]\n",
    "        burrito_sentence = [sentence for sentence in sentences_lower if 'burrito' in sentence]\n",
    "    else:\n",
    "        burrito_sentence = 'Punctuation lacking'\n",
    "    return burrito_sentence \n",
    "\n",
    "def apply_sentiment_intensity_analysis(sentence):\n",
    "    \"\"\"Applies the polarity scores function to a sentence. Used with df.apply(), returns dictionary. \n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    polarity_dict = analyzer.polarity_scores(sentence)\n",
    "    return polarity_dict\n",
    "\n",
    "def find_burrito_sentences_get_sentiment(df):\n",
    "    \"\"\"\n",
    "    Takes the previous two functions and applies them to a dataframe. Finds burrito sentence then gets its polarity scores.\n",
    "    Makes a dataframe with all the individual polarity dictionaries.\n",
    "    \"\"\"\n",
    "    df.reset_index(inplace=True)\n",
    "    df['burrito_sentences'] = df['text'].apply(split_sentences_return_burrito)\n",
    "    polarities_list = []\n",
    "    for indexes, data in df.iterrows():\n",
    "        polarity_dict = apply_sentiment_intensity_analysis(str(data['burrito_sentences']))\n",
    "        polarities_list.append(polarity_dict)\n",
    "    polarities_df = pd.DataFrame(polarities_list)\n",
    "    df = pd.concat([df, polarities_df],axis=1)\n",
    "    return df\n",
    "\n",
    "def n_grams(text):\n",
    "    \"\"\"\n",
    "    Applies ngram function returns bigram. Used with df.apply().\n",
    "    \"\"\"\n",
    "    two_gram = ngrams(text,2)\n",
    "    return list(two_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the two preprocessed dataframes from their pickled files and apply the n_grams function to return bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_path = 'C:/Users/nhcam/Desktop/Springboard/Yelp Burrito Reviews Project/Yelp_Project_Data/reviews_df.pkl'\n",
    "burritos_reviews_path = 'C:/Users/nhcam/Desktop/Springboard/Yelp Burrito Reviews Project/Yelp_Project_Data/burrito_mentions.pkl'\n",
    "reviews_df = pd.read_pickle(all_reviews_path)\n",
    "burritos_df = pd.read_pickle(burritos_reviews_path)\n",
    "\n",
    "burritos_df['bigrams'] = burritos_df['tokenized_text_cleaned'].apply(n_grams)\n",
    "reviews_df['bigrams'] = reviews_df['tokenized_text_cleaned'].apply(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a very simple model first, a simple word tokenized, stop word removed, count vecotrized matrix to predict the binary review target. First split the data into a train and test set. Then instantiate a count vectorizer to convert the tokenized training reviews into a corpus. Finally fit the vectorizer to this corpus. This returns a vocabulary of about 163,000 words (with this split). Wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163455"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(reviews_df['tokenized_text_cleaned'])\n",
    "y = reviews_df['Good/Neutral/Bad']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\n",
    "vectorizer = CountVectorizer(tokenizer=dummy,preprocessor=dummy)\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll transform the training and testing set into a sparse matrix of word counts using the vectorizer's transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X_train = vectorizer.transform(X_train)\n",
    "transformed_X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can train a model on our training set and see how this simple model performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.90      0.93      0.91     53448\n",
      " Neutral/Bad       0.86      0.80      0.83     28785\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     82233\n",
      "   macro avg       0.88      0.87      0.87     82233\n",
      "weighted avg       0.88      0.88      0.88     82233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(transformed_X_train,y_train)\n",
    "y_pred = mnb.predict(transformed_X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple baseline model generalizes pretty well to the testing set! However, it is probably possible to do better with slightly more advanced methods. Let's look at the same process as above with a TFIDF Vectorizer. This will help us weight features that appear in every document lower and may improve the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163717"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=dummy,preprocessor=dummy)\n",
    "tfidf.fit(X_train)\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformed_X_train = vectorizer.transform(X_train)\n",
    "tf_transformed_X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.90      0.93      0.91     53448\n",
      " Neutral/Bad       0.86      0.80      0.83     28785\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     82233\n",
      "   macro avg       0.88      0.87      0.87     82233\n",
      "weighted avg       0.88      0.88      0.88     82233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_mnb = MultinomialNB()\n",
    "tf_mnb.fit(tf_transformed_X_train,y_train)\n",
    "tf_y_pred = tf_mnb.predict(tf_transformed_X_test)\n",
    "print(classification_report(y_test,tf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs exactly the same as the CountVectorizer. This is likely because there are so many unique words in the corpus, especially with the stop words being removed in preprocessing, that the term frequency weighting doesn't add any useful information. The next thing I would like to try is using n-grams instead of just words. With just a word representation we are definitely losing information. Let's look at a CountVectorizer representation starting with bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3411688"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_X = list(reviews_df['bigrams'])\n",
    "y = reviews_df['Good/Neutral/Bad']\n",
    "bigramsX_train,bigramsX_test,bigramsy_train,bigramsy_test = train_test_split(bigrams_X,y,test_size=0.25)\n",
    "\n",
    "bigrams_vectorizer = CountVectorizer(tokenizer=dummy,preprocessor=dummy)\n",
    "bigrams_vectorizer.fit(bigramsX_train)\n",
    "len(bigrams_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramsXtrain_transformed = bigrams_vectorizer.transform(bigramsX_train)\n",
    "bigramsXtest_transformed = bigrams_vectorizer.transform(bigramsX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.90      0.96      0.93     53424\n",
      " Neutral/Bad       0.92      0.79      0.85     28809\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     82233\n",
      "   macro avg       0.91      0.88      0.89     82233\n",
      "weighted avg       0.90      0.90      0.90     82233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_bigrams = MultinomialNB()\n",
    "mnb_bigrams.fit(bigramsXtrain_transformed,bigramsy_train)\n",
    "bigrams_pred = mnb_bigrams.predict(bigramsXtest_transformed)\n",
    "print(classification_report(bigramsy_test,bigrams_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary with the bigrams model has ballooned in size to 3.5 million features. That's a whole heck of a lot. However, using bigrams instead of just words increases the performance of the model by a fair amount. The next piece we'll have to look at is feature reduction because we certainly don't need all 3.5 million bigrams. First we'll run a chi square test between the transformed vectors and the target variable. Then I'll pull out the actual bigrams by name and associate them with their pvalues in a dataframe. The statistically significant pvalues at the 0.05 level will be filtered and pulled out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2,pval = chi2(bigramsXtrain_transformed,bigramsy_train)\n",
    "bigrams = list(bigrams_vectorizer.vocabulary_.keys())\n",
    "order = list(bigrams_vectorizer.vocabulary_.values())\n",
    "\n",
    "bigram_pvalues = pd.DataFrame({'bigram':bigrams},index=order).sort_index()\n",
    "bigram_pvalues['chi2'] = chi2\n",
    "bigram_pvalues['pval'] = pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150709"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant = bigram_pvalues[bigram_pvalues.pval <= 0.05]\n",
    "sig_bigrams = significant['bigram']\n",
    "len(sig_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 3.4 million bigrams, only 150,709 are significant at a p-value of 0.05. Below I've tested different levels of significance and feature exclusion to see which level has the best performance. It is 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for a p-value of: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.93      0.94      0.94     53172\n",
      " Neutral/Bad       0.89      0.87      0.88     29061\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     82233\n",
      "   macro avg       0.91      0.91      0.91     82233\n",
      "weighted avg       0.92      0.92      0.92     82233\n",
      "\n",
      "Classification Report for a p-value of: 0.0005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.92      0.93      0.93     53172\n",
      " Neutral/Bad       0.88      0.85      0.86     29061\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     82233\n",
      "   macro avg       0.90      0.89      0.89     82233\n",
      "weighted avg       0.90      0.90      0.90     82233\n",
      "\n",
      "Classification Report for a p-value of: 5e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.91      0.93      0.92     53172\n",
      " Neutral/Bad       0.87      0.84      0.85     29061\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     82233\n",
      "   macro avg       0.89      0.88      0.89     82233\n",
      "weighted avg       0.90      0.90      0.90     82233\n",
      "\n",
      "Classification Report for a p-value of: 5e-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.91      0.93      0.92     53172\n",
      " Neutral/Bad       0.86      0.83      0.84     29061\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     82233\n",
      "   macro avg       0.88      0.88      0.88     82233\n",
      "weighted avg       0.89      0.89      0.89     82233\n",
      "\n",
      "Classification Report for a p-value of: 5e-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.90      0.92      0.91     53172\n",
      " Neutral/Bad       0.85      0.82      0.84     29061\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     82233\n",
      "   macro avg       0.88      0.87      0.87     82233\n",
      "weighted avg       0.89      0.89      0.89     82233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pvalues = [0.05, 0.0005, 0.000005, 0.00000005, 0.0000000005]\n",
    "for pval in pvalues:\n",
    "    significant = bigram_pvalues[bigram_pvalues.pval <= pval]\n",
    "    sig_bigrams = significant['bigram']\n",
    "    sig_vect = CountVectorizer(tokenizer=dummy,preprocessor=dummy,vocabulary=sig_bigrams)\n",
    "    sig_Xtrain_transformed = sig_vect.transform(bigramsX_train)\n",
    "    sig_Xtest_transformed = sig_vect.transform(bigramsX_test)\n",
    "    mnb_sig = MultinomialNB(alpha=0.1)\n",
    "    mnb_sig.fit(sig_Xtrain_transformed,bigramsy_train)\n",
    "    sig_pred = mnb_sig.predict(sig_Xtest_transformed)\n",
    "    print('Classification Report for a p-value of:', pval)\n",
    "    print(classification_report(bigramsy_test,sig_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this method of only including the 150,709 most significant bigrams, a reduction of 96%, doesn't change the predictive strength of the model at all. It does change the relationship between precision and recall for both classes, but actually increases the f1-score for predicting neutral and bad reviews. Overall this is a better model because it is far simpler, faster and more predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll do a grid search for the best value of the the hyperparameter alpha (0.1) and then try out my model on the burrito set with the vocabulary of bigrams with p <= 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mnb = MultinomialNB()\n",
    "params = {'alpha': [0.01,0.1,1,10]}\n",
    "mnb_grid = GridSearchCV(grid_mnb, param_grid=params,scoring='accuracy')\n",
    "mnb_grid.fit(sig_Xtrain_transformed,bigramsy_train)\n",
    "print(mnb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant = bigram_pvalues[bigram_pvalues.pval <= 0.05]\n",
    "sig_bigrams = significant['bigram']\n",
    "sig_vect = CountVectorizer(tokenizer=dummy,preprocessor=dummy,vocabulary=sig_bigrams)\n",
    "sig_Xtrain_transformed = sig_vect.transform(bigramsX_train)\n",
    "mnb_sig = MultinomialNB(alpha=0.1)\n",
    "mnb_sig.fit(sig_Xtrain_transformed,bigramsy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.89      0.90      0.90     31926\n",
      " Neutral/Bad       0.83      0.81      0.82     18455\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     50381\n",
      "   macro avg       0.86      0.86      0.86     50381\n",
      "weighted avg       0.87      0.87      0.87     50381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First remove all rows that I wasn't able to parse the burrito sentence out.\n",
    "burritos_df = burritos_df[burritos_df['burrito_sentences'] != 'Punctuation lacking']\n",
    "\n",
    "# Then transform the tokenized text into vectors so I can feed it into the model and get predictions.\n",
    "burrito_bigrams = list(burritos_df['bigrams'])\n",
    "burrito_X = sig_vect.transform(burrito_bigrams)\n",
    "y = burritos_df['Good/Neutral/Bad']\n",
    "burrito_pred = mnb_sig.predict(burrito_X)\n",
    "burritos_df['Prediction'] = burrito_pred\n",
    "print(classification_report(y,burrito_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs pretty similarly on this burrito set. Not surprising but good to see it genralizes well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhcam\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Mean Sentiment Score</th>\n",
       "      <th>Mean Stars</th>\n",
       "      <th>Review Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rosarita's Beach</td>\n",
       "      <td>0.508306</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mexquite Mexican Eatery</td>\n",
       "      <td>0.456758</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betitos Mexican Food</td>\n",
       "      <td>0.455457</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super B Burrito</td>\n",
       "      <td>0.454376</td>\n",
       "      <td>3.644444</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burrito's Juarez</td>\n",
       "      <td>0.449913</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Los Picos Parrilla Restaurant</td>\n",
       "      <td>0.446238</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mexico City</td>\n",
       "      <td>0.433089</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chronic Cantina</td>\n",
       "      <td>0.427884</td>\n",
       "      <td>3.684211</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jose' and Tony's Mexican Restaurant</td>\n",
       "      <td>0.423275</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amigos Tacos</td>\n",
       "      <td>0.417572</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Restaurant Name  Mean Sentiment Score  Mean Stars  \\\n",
       "0                     Rosarita's Beach              0.508306    3.375000   \n",
       "1              Mexquite Mexican Eatery              0.456758    4.000000   \n",
       "2                 Betitos Mexican Food              0.455457    4.285714   \n",
       "3                      Super B Burrito              0.454376    3.644444   \n",
       "4                     Burrito's Juarez              0.449913    3.600000   \n",
       "5        Los Picos Parrilla Restaurant              0.446238    3.769231   \n",
       "6                          Mexico City              0.433089    3.388889   \n",
       "7                      Chronic Cantina              0.427884    3.684211   \n",
       "8  Jose' and Tony's Mexican Restaurant              0.423275    3.250000   \n",
       "9                         Amigos Tacos              0.417572    3.916667   \n",
       "\n",
       "   Review Count  \n",
       "0            16  \n",
       "1            12  \n",
       "2            14  \n",
       "3           135  \n",
       "4            15  \n",
       "5            13  \n",
       "6            18  \n",
       "7            19  \n",
       "8            12  \n",
       "9            36  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all unique burrito restaurants and intialize a dictionary\n",
    "\n",
    "unique_restaurants = burritos_df['Restaurant Name'].unique()\n",
    "name_sentiment_dict = {}\n",
    "\n",
    "# iterate over the unique restaurants, take the ones with more than 10 reviews and put their burrito score in a dictionary\n",
    "for restaurant in unique_restaurants:\n",
    "    given_res = burritos_df.loc[burritos_df['Restaurant Name'] == restaurant]\n",
    "    if len(given_res) > 10:\n",
    "        mean = given_res['compound'].mean()\n",
    "        name_sentiment_dict[restaurant] = mean\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Push dictionary to dataframe, sort by sentiment score and then rename columns for joining operation    \n",
    "undervalued_burritos = pd.DataFrame.from_dict(name_sentiment_dict,orient = 'index', columns = ['Mean Sentiment Score'])\n",
    "undervalued_burritos.sort_values(by=['Mean Sentiment Score'],ascending = False,inplace=True)\n",
    "undervalued_burritos = undervalued_burritos.reset_index()\n",
    "undervalued_burritos.columns = ['Restaurant Name','Mean Sentiment Score']\n",
    "\n",
    "# Take restaurant name and stars, group by restaurant name and aggregate to get average star rating and total reviews > 10\n",
    "burrito_stars = burritos_df[['Restaurant Name','stars']].groupby(['Restaurant Name']).agg(['mean','count'])\n",
    "burrito_stars = burrito_stars.loc[burrito_stars['stars']['count'] > 10 ]\n",
    "#burrito_stars = burrito_stars.sort_values(('stars','mean'), ascending=False)\n",
    "\n",
    "# Then join on restaurant name to see how burrito sentiment maps to average star rating\n",
    "undervalued_burritos = undervalued_burritos.join(burrito_stars, on='Restaurant Name')\n",
    "undervalued_burritos.columns = ['Restaurant Name','Mean Sentiment Score','Mean Stars','Review Count']\n",
    "undervalued_burritos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Mean Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pollos LaChuya</td>\n",
       "      <td>4.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cocina Madrigal</td>\n",
       "      <td>4.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Garden Grill</td>\n",
       "      <td>4.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Frescos Cocina Mexicana</td>\n",
       "      <td>4.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kiss Pollos Estilo Sinaloa</td>\n",
       "      <td>4.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La Purisima Bakery</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>El Cordobes</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Del Yaqui</td>\n",
       "      <td>4.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Humberto's Mexican Food</td>\n",
       "      <td>4.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tacos Kissi</td>\n",
       "      <td>4.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Restaurant Name  Mean Stars\n",
       "0              Pollos LaChuya    4.916667\n",
       "1             Cocina Madrigal    4.875000\n",
       "2                Garden Grill    4.846154\n",
       "3  El Frescos Cocina Mexicana    4.812500\n",
       "4  Kiss Pollos Estilo Sinaloa    4.769231\n",
       "5          La Purisima Bakery    4.750000\n",
       "6                 El Cordobes    4.750000\n",
       "7                   Del Yaqui    4.727273\n",
       "8     Humberto's Mexican Food    4.727273\n",
       "9                 Tacos Kissi    4.714286"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find highest starred restaurants with burrito reviews, same process as above\n",
    "\n",
    "#burritos_df.reset_index(inplace=True)\n",
    "unique_restaurants = burritos_df['Restaurant Name'].unique()\n",
    "name_sentiment_dict = {}\n",
    "\n",
    "# iterate over the unique restaurants, take the ones with more than 10 reviews and put their burrito score in a dictionary\n",
    "for restaurant in unique_restaurants:\n",
    "    given_res = burritos_df.loc[burritos_df['Restaurant Name'] == restaurant]\n",
    "    if len(given_res) > 10:\n",
    "        mean = given_res['stars'].mean()\n",
    "        name_sentiment_dict[restaurant] = mean\n",
    "    else:\n",
    "        pass\n",
    "starred_burritos = pd.DataFrame.from_dict(name_sentiment_dict,orient = 'index', columns = ['Stars'])\n",
    "starred_burritos.head()\n",
    "starred_burritos.sort_values(by=['Stars'],ascending = False,inplace=True)\n",
    "starred_burritos = starred_burritos.reset_index()\n",
    "starred_burritos.columns = ['Restaurant Name','Mean Stars']\n",
    "starred_burritos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">stars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Geo's tacos</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taqueria La Herradura</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicali Tacos</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Casa De Falafel</th>\n",
       "      <td>4.955556</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Bamba Mexican Grill Restaurant</th>\n",
       "      <td>4.951220</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El Pollito Charro</th>\n",
       "      <td>4.935484</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando's Food</th>\n",
       "      <td>4.933333</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bajamar Seafood &amp; Tacos</th>\n",
       "      <td>4.921986</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cocina Madrigal</th>\n",
       "      <td>4.916667</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taco San Francisco</th>\n",
       "      <td>4.894737</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      stars      \n",
       "                                       mean count\n",
       "Restaurant Name                                  \n",
       "Geo's tacos                        5.000000    24\n",
       "Taqueria La Herradura              5.000000    13\n",
       "Chicali Tacos                      5.000000    16\n",
       "Casa De Falafel                    4.955556    90\n",
       "La Bamba Mexican Grill Restaurant  4.951220    41\n",
       "El Pollito Charro                  4.935484    31\n",
       "Fernando's Food                    4.933333    30\n",
       "Bajamar Seafood & Tacos            4.921986   282\n",
       "Cocina Madrigal                    4.916667   120\n",
       "Taco San Francisco                 4.894737    19"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same process as above but with the whole reviews dataframe\n",
    "\n",
    "stars_by_place = reviews_df[['Restaurant Name','stars']].groupby(['Restaurant Name']).agg(['mean','count'])\n",
    "stars_by_place = stars_by_place.loc[stars_by_place['stars']['count'] > 10 ]\n",
    "stars_by_place = stars_by_place.sort_values(('stars','mean'), ascending=False)\n",
    "stars_by_place.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
